{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b93fe4-d49a-4600-90a5-b8ce2a5e625b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/dev/human'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/root/dev/human/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b349812-98fd-47dc-a0af-addfa0f804a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f4f0cc-11ad-4cdf-a853-3dd27bec7945",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mb4d440a4085d              \u001b[m  Mon Oct  7 21:58:18 2024  \u001b[1m\u001b[30m550.100\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 38°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  396\u001b[m / \u001b[33m24564\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ea33a-456c-4aad-b1ee-8ba467c6d211",
   "metadata": {},
   "source": [
    "# Selective scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce6c2b-4fa6-4566-9065-82cfef27cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_state_update(state, x, dt, A, B, C, D=None, z=None, dt_bias=None, dt_softplus=False):\n",
    "    has_heads = state.dim() > 3\n",
    "    if state.dim() == 3:\n",
    "        state = state.unsqueeze(1) # (B, num_h, D, H) → H might be dimension of state (dstate, originally)\n",
    "    if x.dim() == 2:\n",
    "        x = x.unsqueeze(1) # (B, num_h, D) → number of heads\n",
    "    if dt.dim() == 2:\n",
    "        dt = dt.unsqueeze(1) # (B, num_h, D)\n",
    "    if A.dim() == 2:\n",
    "        A = A.unsqueeze(0) # (D, H)\n",
    "    if B.dim() == 2:\n",
    "        B = B.unsqueeze(1) # (B, num_groups, H)\n",
    "    if C.dim() == 2:\n",
    "        C = C.unsqueeze(1) # (B, num_groups, H)\n",
    "    if D is not None and D.dim() == 1:\n",
    "        D = D.unsqueeze(0) # (num_h, D)\n",
    "    if z is not None and z.dim() == 2:\n",
    "        z = z.unsqueeze(1)\n",
    "    if dt_bias is not None and dt_bias.dim() == 1:\n",
    "        dt_bias = dt_bias.unsqueeze(0)\n",
    "    \n",
    "    batch, nheads, dim, dstate = state.shape\n",
    "    assert x.shape == (batch, nheads, dim)\n",
    "    assert dt.shape == x.shape\n",
    "    assert A.shape == (nheads, dim, dstate)\n",
    "    ngroups = B.shape[1]\n",
    "    assert nheads % ngroups == 0, \"nheads must be divisible by ngroups\"\n",
    "    assert B.shape == (batch, ngroups, dstate)\n",
    "    assert C.shape == B.shape\n",
    "    if D is not None:\n",
    "        assert D.shape == (nheads, dim)\n",
    "    if z is not None:\n",
    "        assert z.shape == x.shape\n",
    "    if dt_bias is not None:\n",
    "        assert dt_bias.shape == (nheads, dim)\n",
    "    \n",
    "    out = torch.empty_like(x)\n",
    "    grid = lambda META: (triton.cdiv(dim, META['BLOCK_SIZE_M']), batch, nheads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjuke_39_231",
   "language": "python",
   "name": "jjuke_39_231"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
