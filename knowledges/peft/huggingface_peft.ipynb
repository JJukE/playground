{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa071e71-623a-40f7-beba-450f1acfba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/dev/hf/diffusers/examples/triplane_diffusion'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/root/dev/hf/diffusers/examples/triplane_diffusion\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb09e45-4494-4617-b4f1-241410c658b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m6f37a742720d              \u001b[m  Fri Apr 12 15:43:31 2024  \u001b[1m\u001b[30m525.89.02\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 42°C\u001b[m, \u001b[32m 20 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1033\u001b[m / \u001b[33m24564\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 38°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m24564\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8a1154-37de-475f-8576-b1ab7bad1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da50865-1080-4846-8276-05bb1bde6c63",
   "metadata": {},
   "source": [
    "# Huggingface PEFT tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d370393-40ad-4580-958d-aa4e2e710250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peft version:  0.10.0\n",
      "accelerate version:  0.29.1\n",
      "datasets version:  2.18.0\n",
      "transformers version:  4.39.3\n",
      "diffusers version:  0.27.2\n"
     ]
    }
   ],
   "source": [
    "import peft\n",
    "import accelerate\n",
    "import datasets\n",
    "import transformers\n",
    "import diffusers\n",
    "\n",
    "print(\"peft version: \", peft.__version__)\n",
    "print(\"accelerate version: \", accelerate.__version__)\n",
    "print(\"datasets version: \", datasets.__version__)\n",
    "print(\"transformers version: \", transformers.__version__)\n",
    "print(\"diffusers version: \", diffusers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bfcf2d-284e-4e31-93ee-8e9c3f4640e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DConditionModel\n",
    "\n",
    "# unet = UNet2DConditionModel.from_pretrained(\n",
    "#     \"stabilityai/stable-diffusion-xl-base-1.0\", subfolder=\"unet\"\n",
    "# )\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-base\", subfolder=\"unet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117bff86-5e8f-4605-b06d-2d6352fb5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ce4a5e-afa6-44ec-b175-2503e1a66b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet.to(device)\n",
    "# x = torch.rand((8, 4, 64, 64)).to(device)\n",
    "# time_step = torch.randn((8,)).to(device)\n",
    "# enc_h = torch.rand((8, 77, 1024)).to(device)\n",
    "# output = unet(x, timestep=time_step, encoder_hidden_states=enc_h).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4a7e66-302b-4699-8b2d-40f710e1efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params:  865910724\n"
     ]
    }
   ],
   "source": [
    "model_size = 0\n",
    "for param in unet.parameters():\n",
    "    model_size += param.data.nelement()\n",
    "print(\"trainable params: \", model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9262e31-7422-4846-a653-e740b9205a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find modules\n",
    "def find_modules(module, module_types):\n",
    "    matching_modules = []\n",
    "    for name, mod in module.named_modules():\n",
    "        if isinstance(mod, module_types):\n",
    "            module_name = name.split(\".\")[-1]\n",
    "            if len(module_name) == 1:\n",
    "                # print(name)\n",
    "                module_name = name\n",
    "            matching_modules.append(module_name)\n",
    "    return matching_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47f908a-3fd2-4c85-8988-16338f08b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0', 'conv_out', 'up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2', 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0', 'up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0', 'up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0', 'conv_shortcut', 'proj_in', 'up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0', 'up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0', 'up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0', 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0', 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2', 'to_v', 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0', 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2', 'time_emb_proj', 'conv1', 'up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2', 'linear_2', 'up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2', 'mid_block.attentions.0.transformer_blocks.0.ff.net.2', 'up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0', 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0', 'up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2', 'up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0', 'up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2', 'linear_1', 'to_q', 'up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2', 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0', 'up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2', 'up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2', 'up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0', 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2', 'to_k', 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2', 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0', 'up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0', 'up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0', 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2', 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0', 'up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0', 'conv2', 'proj', 'up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0', 'conv', 'up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0', 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0', 'proj_out', 'up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0', 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0', 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0', 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2', 'conv_in', 'up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0', 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0', 'up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0', 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0', 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0', 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0', 'up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0', 'up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2']\n"
     ]
    }
   ],
   "source": [
    "module_types = (torch.nn.Linear, torch.nn.Embedding, torch.nn.Conv2d)\n",
    "target_modules = find_modules(unet, module_types)\n",
    "target_modules = list(set(target_modules))\n",
    "print(target_modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb3529-b565-424b-8f22-fc486446e3b0",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5ba05f-c288-4fc8-b1b5-54bc2b0d493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 829,952 || all params: 866,740,676 || trainable%: 0.09575551522864031\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "unet_lora = unet.to(device)\n",
    "\n",
    "# freeze params of models to save more memory\n",
    "unet_lora.requires_grad_(False)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=4,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"],\n",
    "    init_lora_weights= \"gaussian\",\n",
    "    bias=\"none\"\n",
    ") # scale = alpha / r\n",
    "\n",
    "unet_lora.add_adapter(config)\n",
    "lora_layers = filter(lambda p: p.requires_grad, unet.parameters())\n",
    "\n",
    "trainable_params = 0\n",
    "all_params = 0\n",
    "for _, param in unet.named_parameters():\n",
    "    num_params = param.numel()\n",
    "    all_params += num_params\n",
    "    if param.requires_grad:\n",
    "        trainable_params += num_params\n",
    "print(f\"trainable params: {trainable_params:,d} || all params: {all_params:,d} || trainable%: {100 * trainable_params / all_params}\")\n",
    "unet_lora.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a434d80-df53-4511-b9d2-b29e5cb116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((8, 4, 64, 64)).to(device)\n",
    "time_step = torch.randn((8,)).to(device)\n",
    "enc_h = torch.rand((8, 77, 1024)).to(device)\n",
    "output = unet_lora(x, timestep=time_step, encoder_hidden_states=enc_h).sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eae1fe-5595-4fcc-b6f7-6354b5758e6d",
   "metadata": {},
   "source": [
    "## LoKr (slightly different to KAdaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "369b6d2d-6f83-4e3c-8b0c-d835306fb582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 112,448 || all params: 866,023,172 || trainable%: 0.012984410075346113\n"
     ]
    }
   ],
   "source": [
    "from peft import LoKrConfig, get_peft_model\n",
    "\n",
    "unet_lokr = unet.to(device)\n",
    "\n",
    "# freeze params of models to save more memory\n",
    "unet_lokr.requires_grad_(False)\n",
    "\n",
    "config = LoKrConfig(\n",
    "    r=4,\n",
    "    alpha=4,\n",
    "    # rank_dropout=0.1,\n",
    "    module_dropout=0.1,\n",
    "    use_effective_conv2d=True,\n",
    "    target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"]\n",
    ")\n",
    "\n",
    "unet_lokr.add_adapter(config)\n",
    "lokr_layers = filter(lambda p: p.requires_grad, unet.parameters())\n",
    "\n",
    "trainable_params = 0\n",
    "all_params = 0\n",
    "for _, param in unet.named_parameters():\n",
    "    num_params = param.numel()\n",
    "    all_params += num_params\n",
    "    if param.requires_grad:\n",
    "        trainable_params += num_params\n",
    "print(f\"trainable params: {trainable_params:,d} || all params: {all_params:,d} || trainable%: {100 * trainable_params / all_params}\")\n",
    "unet_lokr.train();\n",
    "# unet = get_peft_model(unet, config).to(device)\n",
    "# unet.print_trainable_parameters()\n",
    "# unet.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62877435-3c80-43aa-85fb-dd73216c4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((8, 4, 64, 64)).to(device)\n",
    "time_step = torch.randn((8,)).to(device)\n",
    "enc_h = torch.rand((8, 77, 1024)).to(device)\n",
    "output = unet(x, timestep=time_step, encoder_hidden_states=enc_h).sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163b3cc-0336-4acd-a43a-ac0503b08499",
   "metadata": {},
   "source": [
    "# Layer replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd7589fe-1994-44f4-ab7a-f36f99cee7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,0,2,0,3,1,2,1,3,2,3], dtype=torch.long, device='cuda').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149df4f5-3875-41e7-8adb-3ea9565b5aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_test",
   "language": "python",
   "name": "hf_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
