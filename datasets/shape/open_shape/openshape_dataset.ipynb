{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f63dfc-ba54-4a75-95a7-7967cbb7bd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/dev/hf/diffusers/examples/triplane_diffusion'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/root/dev/hf/diffusers/examples/triplane_diffusion\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768310c6-c0fc-4da3-ad20-a491381b17bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37m6f37a742720d              \u001b[m  Wed Apr  3 00:43:48 2024  \u001b[1m\u001b[30m525.89.02\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 42°C\u001b[m, \u001b[32m 20 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1028\u001b[m / \u001b[33m24564\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 37°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m24564\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92e6e0cb-78c3-4c00-af44-075b0449ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299e604-b8d7-4db2-8d41-b6567319c5e0",
   "metadata": {},
   "source": [
    "# Explanation of the OpenShape Dataset\n",
    "\n",
    "From OpenShape official [code](https://github.com/Colin97/OpenShape_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfb1317c-e035-4b98-81aa-0c1209713bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objaverse  download_data.py  meta_data\tmeta_data.zip  objaverse-processed\n"
     ]
    }
   ],
   "source": [
    "!ls \"/root/hdd2/OpenShape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf4168d-a4ae-4c1b-b2d6-a73f00bf861e",
   "metadata": {},
   "source": [
    "## Meta Data\n",
    "\n",
    "```meta_data.zip``` includes the meta data used for __training (Objaverse, ShapeNet, ABO, and 3D-FUTURE)__ and __evaluation (on Objaverse-LVIS, ModelNet40, and ScanObjectNN)__:\n",
    "\n",
    "- ```gpt4_filtering.json```: Filtering results of Objaverse raw texts, __generated with GPT4__.\n",
    "- ```point_feat_knn.npy```: KNN indices calculated using shape features, used for hard mining during training.\n",
    "\n",
    "- ```modelnet40/```\n",
    "    - ```test_split.json```: List of ModelNet40 test shapes.\n",
    "    - ```test_pc.npy```: Point clouds of ModelNet40 test shapes, 10000 x 3.\n",
    "    - ```cat_name_pt_feat.npy```: Text features of ModelNet40 category names, __prompt engineering used__.\n",
    "\n",
    "- ```lvis_cat_name_pt_feat.npy```: Text features of Objeverse-LVIS category names, __prompt engineering used__.\n",
    "\n",
    "- ```scanobjectnn/```\n",
    "    - ```xyz_label.npy```: Point clouds and labels of ScanObjectNN test shapes.\n",
    "    - ```cat_name_pt_feat.npy```: Text features of ScanObjectNN category names, __prompt engineering used__.\n",
    "- All text features are extracted using OpenCLIP (ViT-bigG-14, laion2b_s39b_b160k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe7070b-3a0e-41d8-804e-5bc8d6755c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_filtering.json\t   modelnet40\t       scanobjectnn\n",
      "lvis_cat_name_pt_feat.npy  point_feat_knn.npy  split\n"
     ]
    }
   ],
   "source": [
    "!ls \"/root/hdd2/OpenShape/meta_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ce3966-34ba-4f7f-a1fa-8b95ba635c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98ad4df-079b-4c95-aab4-ccb5bc44b3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/openshape_train.yaml'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnet40_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77ab41a-a663-40cf-a347-13584c23aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from jjuke.net_utils import instantiate_from_config\n",
    "\n",
    "# Change dataset.py corresponding to instantiate_from_config\n",
    "modelnet40_config = \"\"\"\n",
    "    target: dataset.dataset.make_modelnet40test\n",
    "    params:\n",
    "        config:\n",
    "            modelnet40:\n",
    "                test_split: /root/hdd2/OpenShape/meta_data/modelnet40/test_split.json\n",
    "                test_pc: /root/hdd2/OpenShape/meta_data/modelnet40/test_pc.npy\n",
    "                num_points: 10000 \n",
    "                num_workers: 0\n",
    "                test_batch_size: 100\n",
    "                clip_feat_path: /root/hdd2/OpenShape/meta_data/modelnet40/cat_name_pt_feat.npy\n",
    "                y_up: True\n",
    "            dataset:\n",
    "                use_color: True\n",
    "\"\"\"\n",
    "modelnet40_config = yaml.safe_load(modelnet40_config)\n",
    "modelnet40_dl = instantiate_from_config(modelnet40_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce94ea4e-0e59-430f-b8aa-afef50a91a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnet_data = next(iter(modelnet40_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc86b6d-5389-42f3-a6b0-49e49b41b081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xyz', 'features', 'xyz_dense', 'features_dense', 'name', 'category'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnet_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe29fe9c-d771-477f-8a6c-907872997a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dataset.py corresponding to instantiate_from_config\n",
    "objaverselvis_config = \"\"\"\n",
    "    target: dataset.dataset.make_objaverse_lvis\n",
    "    params:\n",
    "        config:\n",
    "            objaverse_lvis:\n",
    "                split: /root/hdd2/OpenShape/meta_data/split/lvis.json\n",
    "                clip_feat_path: /root/hdd2/OpenShape/meta_data/lvis_cat_name_pt_feat.npy\n",
    "                num_points: 10000 \n",
    "                num_workers: 6\n",
    "                batch_size: 100\n",
    "                y_up: True\n",
    "                normalize: True\n",
    "                use_color: True\n",
    "\"\"\"\n",
    "objaverselvis_config = yaml.safe_load(objaverselvis_config)\n",
    "objaverselvis_dl = instantiate_from_config(objaverselvis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e799f67-ff43-4b1a-bf1b-c8aed34292c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 502, in __getitem__\n    data = np.load(self.split[index]['data_path'], allow_pickle=True).item()\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/data/objaverse-processed/merged_for_training_final/Objaverse/000-090/d4c9180a46cf401fa24fa3afe9237a43.npy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m objaverselvis_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobjaverselvis_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m objaverselvis_data\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 502, in __getitem__\n    data = np.load(self.split[index]['data_path'], allow_pickle=True).item()\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/data/objaverse-processed/merged_for_training_final/Objaverse/000-090/d4c9180a46cf401fa24fa3afe9237a43.npy'\n"
     ]
    }
   ],
   "source": [
    "# TODO: Edit json file to have only data name and use data_dir!\n",
    "objaverselvis_data = next(iter(objaverselvis_dl))\n",
    "objaverselvis_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9395688-ed56-4145-aa14-4d28522fcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanobjectnn_config = \"\"\"\n",
    "    target: dataset.dataset.make_scanobjectnntest\n",
    "    params:\n",
    "        config:\n",
    "            scanobjectnn:\n",
    "                data_path: /root/hdd2/OpenShape/meta_data/scanobjectnn/xyz_label.npy \n",
    "                num_points: 10000 \n",
    "                num_workers: 0\n",
    "                test_batch_size: 100\n",
    "                clip_feat_path: /root/hdd2/OpenShape/meta_data/scanobjectnn/cat_name_pt_feat.npy\n",
    "                y_up: True\n",
    "            dataset:\n",
    "                use_color: True\n",
    "\"\"\"\n",
    "scanobjectnn_config = yaml.safe_load(scanobjectnn_config)\n",
    "scanobjectnn_dl = instantiate_from_config(scanobjectnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06e0ffcd-7d49-411c-b043-ec85317afa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['xyz', 'features', 'xyz_dense', 'features_dense', 'name', 'category'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanobjectnn_data = next(iter(scanobjectnn_dl))\n",
    "scanobjectnn_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e64e83-5fb1-458c-a618-1a139cf18027",
   "metadata": {},
   "source": [
    "- ```split/```: List of training shapes.\n",
    "    - ```train_all.json```: Training with __four datasets (Objaverse, ShapeNet, ABO, and 3D-FUTURE)__.\n",
    "    - ```train_no_lvis.json```: Training with four datasets but __Objaverse-LVIS shapes excluded__.\n",
    "    - ```ablation/train_shapenet_only.json```: Training with __ShapeNet shapes only__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebba7aae-7815-4cb7-b10f-07325a7b97c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ablation  lvis.json  train_all.json  train_no_lvis.json\n"
     ]
    }
   ],
   "source": [
    "!ls \"/root/hdd2/OpenShape/meta_data/split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b05af1fd-c634-421a-92e8-aa891d36c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dataset.py corresponding to instantiate_from_config\n",
    "# train_config = \"\"\"\n",
    "#     target: dataset.dataset.Four\n",
    "#     params:\n",
    "#         config:\n",
    "#             dataset:\n",
    "#                 name: Four\n",
    "#                 train_split: /root/hdd2/OpenShape/meta_data/split/train_all.json # [\".../train_no_lvis.json\", \".../ablation/train_shapenet_only.json\"]\n",
    "#                 train_partial: -1\n",
    "#                 num_points: 10000 \n",
    "#                 num_workers: 6\n",
    "#                 train_batch_size: 200\n",
    "#                 use_knn_negative_sample: False\n",
    "#                 negative_sample_num: 1\n",
    "#                 knn_path: /root/hdd2/OpenShape/meta_data/point_feat_knn.npy\n",
    "#                 y_up: True\n",
    "#                 normalize: True\n",
    "#                 random_z_rotate: True\n",
    "#                 use_color: True\n",
    "#                 rgb_random_drop_prob: 0.5\n",
    "#                 augment: True\n",
    "#                 text_source: [text, caption, retrieval_text] \n",
    "#                 use_text_filtering: True\n",
    "#                 use_prompt_engineering: True\n",
    "#                 gpt4_filtering_path: /root/hdd2/OpenShape/meta_data/gpt4_filtering.json\n",
    "#         phase: \"train\"\n",
    "# \"\"\"\n",
    "train_config = \"\"\"\n",
    "    target: dataset.dataset.Four\n",
    "    params:\n",
    "        config:\n",
    "            dataset:\n",
    "                name: Four\n",
    "                train_split: /root/hdd2/OpenShape/meta_data/split/ablation/train_shapenet_only.json\n",
    "                train_partial: -1\n",
    "                num_points: 10000 \n",
    "                num_workers: 6\n",
    "                train_batch_size: 200\n",
    "                use_knn_negative_sample: False\n",
    "                negative_sample_num: 1\n",
    "                knn_path: /root/hdd2/OpenShape/meta_data/point_feat_knn.npy\n",
    "                y_up: True\n",
    "                normalize: True\n",
    "                random_z_rotate: True\n",
    "                use_color: True\n",
    "                rgb_random_drop_prob: 0.5\n",
    "                augment: True\n",
    "                text_source: [text, caption, retrieval_text] \n",
    "                use_text_filtering: True\n",
    "                use_prompt_engineering: True\n",
    "                gpt4_filtering_path: /root/hdd2/OpenShape/meta_data/gpt4_filtering.json\n",
    "        phase: \"train\"\n",
    "\"\"\"\n",
    "train_config = yaml.safe_load(train_config)\n",
    "train_ds = instantiate_from_config(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cbf159a-4b2e-4c40-bc1e-8a75c8a6f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import minkowski_collate_fn\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    num_workers=train_config[\"params\"][\"config\"][\"dataset\"][\"num_workers\"],\n",
    "    collate_fn=minkowski_collate_fn,\n",
    "    batch_size=train_config[\"params\"][\"config\"][\"dataset\"][\"train_batch_size\"],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "663b30a8-fd1b-4524-a85c-231a66294f7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 353, in __getitem__\n    return self.get_others(self.split[index])\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 276, in get_others\n    data = np.load(meta['data_path'], allow_pickle=True).item()\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/data/objaverse-processed/merged_for_training_final/ShapeNet/04330267/2c4eb370f10b4667e6a1cd9763fc2f3f.npy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trian_data\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 353, in __getitem__\n    return self.get_others(self.split[index])\n  File \"/root/dev/hf/diffusers/examples/triplane_diffusion/dataset/dataset.py\", line 276, in get_others\n    data = np.load(meta['data_path'], allow_pickle=True).item()\n  File \"/opt/conda/envs/sgtd/lib/python3.9/site-packages/numpy/lib/npyio.py\", line 427, in load\n    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\nFileNotFoundError: [Errno 2] No such file or directory: '/mnt/data/objaverse-processed/merged_for_training_final/ShapeNet/04330267/2c4eb370f10b4667e6a1cd9763fc2f3f.npy'\n"
     ]
    }
   ],
   "source": [
    "# TODO: Edit json file to have only data name and use data_dir!\n",
    "train_data = next(iter(train_dl))\n",
    "trian_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7fa05-735f-4986-b171-411bb4c5b7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgtd",
   "language": "python",
   "name": "sgtd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
